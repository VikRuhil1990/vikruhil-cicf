{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8cce118b",
   "metadata": {},
   "source": [
    "# CICF Week 12\n",
    "\n",
    "This notebook builds a neural network model for predicting survival using the Titanic dataset from the previous week.\n",
    "\n",
    "This notebook borrows from Jeremy Howard's execellent course, [lesson 5](https://github.com/fastai/course22/blob/master/05-linear-model-and-neural-net-from-scratch.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "28c7fe9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, numpy as np, pandas as pd\n",
    "np.set_printoptions(linewidth=140)\n",
    "torch.set_printoptions(linewidth=140, sci_mode=False, edgeitems=7)\n",
    "pd.set_option('display.width', 140)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8f2a4d6",
   "metadata": {},
   "source": [
    "Before we look at the Titanic dataset, we are first going to look at how PyTorch can caluclate deriatives.\n",
    "PyTorch is a library extending the NumPy arrays that adds many functions to faciliate working with neural networks. It can also move calculations to a GPU for speed, something that NumPy doesn't do itself.\n",
    "\n",
    "The fundamental PyTorch datatype is the `tensor`. It is similar to an array of numbers.\n",
    "Tensors have a _rank_, which is akin to the number of dimensions it has, and a _shape_ which is the number of columns it has in each dimension.\n",
    "\n",
    "The key thing for tensors is that PyTorch will remember how they are used in a computation so that it can calculate the derivative for each parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d8c23afb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3., requires_grad=True)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def f(x): return x**2\n",
    "\n",
    "a = torch.tensor(3.)\n",
    "a.requires_grad_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "11950458",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(9., grad_fn=<PowBackward0>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yt = f(a)\n",
    "yt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9e69e3c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(6.)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yt.backward()\n",
    "a.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "982116c6-7e1d-4a9a-8123-22ebc89076af",
   "metadata": {},
   "source": [
    "Now lets use the titanic dataset and build a neural network classifier for it. First, load the Titanic dataset and prepare it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1f07ba7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>887</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Montvila, Rev. Juozas</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>211536</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>888</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Graham, Miss. Margaret Edith</td>\n",
       "      <td>female</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>112053</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>B42</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>889</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Johnston, Miss. Catherine Helen \"Carrie\"</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>W./C. 6607</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>890</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Behr, Mr. Karl Howell</td>\n",
       "      <td>male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>111369</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>C148</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>891</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Dooley, Mr. Patrick</td>\n",
       "      <td>male</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>370376</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived  Pclass                                               Name     Sex   Age  SibSp  Parch            Ticket  \\\n",
       "0              1         0       3                            Braund, Mr. Owen Harris    male  22.0      1      0         A/5 21171   \n",
       "1              2         1       1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1      0          PC 17599   \n",
       "2              3         1       3                             Heikkinen, Miss. Laina  female  26.0      0      0  STON/O2. 3101282   \n",
       "3              4         1       1       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1      0            113803   \n",
       "4              5         0       3                           Allen, Mr. William Henry    male  35.0      0      0            373450   \n",
       "..           ...       ...     ...                                                ...     ...   ...    ...    ...               ...   \n",
       "886          887         0       2                              Montvila, Rev. Juozas    male  27.0      0      0            211536   \n",
       "887          888         1       1                       Graham, Miss. Margaret Edith  female  19.0      0      0            112053   \n",
       "888          889         0       3           Johnston, Miss. Catherine Helen \"Carrie\"  female   NaN      1      2        W./C. 6607   \n",
       "889          890         1       1                              Behr, Mr. Karl Howell    male  26.0      0      0            111369   \n",
       "890          891         0       3                                Dooley, Mr. Patrick    male  32.0      0      0            370376   \n",
       "\n",
       "        Fare Cabin Embarked  \n",
       "0     7.2500   NaN        S  \n",
       "1    71.2833   C85        C  \n",
       "2     7.9250   NaN        S  \n",
       "3    53.1000  C123        S  \n",
       "4     8.0500   NaN        S  \n",
       "..       ...   ...      ...  \n",
       "886  13.0000   NaN        S  \n",
       "887  30.0000   B42        S  \n",
       "888  23.4500   NaN        S  \n",
       "889  30.0000  C148        C  \n",
       "890   7.7500   NaN        Q  \n",
       "\n",
       "[891 rows x 12 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../week11-machine-learning/titanic.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d87f260c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      0\n",
       "Survived         0\n",
       "Pclass           0\n",
       "Name             0\n",
       "Sex              0\n",
       "Age            177\n",
       "SibSp            0\n",
       "Parch            0\n",
       "Ticket           0\n",
       "Fare             0\n",
       "Cabin          687\n",
       "Embarked         2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "77bfc235",
   "metadata": {},
   "outputs": [],
   "source": [
    "modes = df.mode().iloc[0]\n",
    "df.fillna(modes, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e2d3a371",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.383838</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>28.566970</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>32.204208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>257.353842</td>\n",
       "      <td>0.486592</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>13.199572</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>49.693429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>223.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.910400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>668.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PassengerId    Survived      Pclass         Age       SibSp       Parch        Fare\n",
       "count   891.000000  891.000000  891.000000  891.000000  891.000000  891.000000  891.000000\n",
       "mean    446.000000    0.383838    2.308642   28.566970    0.523008    0.381594   32.204208\n",
       "std     257.353842    0.486592    0.836071   13.199572    1.102743    0.806057   49.693429\n",
       "min       1.000000    0.000000    1.000000    0.420000    0.000000    0.000000    0.000000\n",
       "25%     223.500000    0.000000    2.000000   22.000000    0.000000    0.000000    7.910400\n",
       "50%     446.000000    0.000000    3.000000   24.000000    0.000000    0.000000   14.454200\n",
       "75%     668.500000    1.000000    3.000000   35.000000    1.000000    0.000000   31.000000\n",
       "max     891.000000    1.000000    3.000000   80.000000    8.000000    6.000000  512.329200"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3201971d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['LogFare'] = np.log(df['Fare']+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "03156d1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['PassengerId', 'Survived', 'Name', 'Age', 'SibSp', 'Parch', 'Ticket', 'Fare', 'Cabin', 'LogFare', 'Sex_female', 'Sex_male',\n",
       "       'Pclass_1', 'Pclass_2', 'Pclass_3', 'Embarked_C', 'Embarked_Q', 'Embarked_S'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.get_dummies(df, columns=[\"Sex\", \"Pclass\", \"Embarked\"], dtype=float)\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e41f6516",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import tensor\n",
    "t_dep = tensor(df.Survived)\n",
    "cols=['Age','SibSp','Parch','LogFare','Sex_male','Sex_female','Pclass_1','Pclass_2','Pclass_3','Embarked_C','Embarked_Q','Embarked_S']\n",
    "t_indep=tensor(df[cols].values, dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "46e1441c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([891, 12])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_indep.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1bb334d",
   "metadata": {},
   "source": [
    "Normalize each column to only have values between 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ecd67371",
   "metadata": {},
   "outputs": [],
   "source": [
    "vals,_ = t_indep.max(dim=0)\n",
    "t_indep = t_indep / vals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a363185b",
   "metadata": {},
   "source": [
    "We are going to make the same model that we used in the spreadsheet: two sets of weights which are multiplied by the independent columns. Then a non-negative function (aka $max(0,x)$ aka ReLU), and then added together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0269961f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "torch.manual_seed(442)\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(12,2, dtype=float),\n",
    "    nn.ReLU(),\n",
    ")\n",
    "def calc_preds(x):\n",
    "    y = model(x)\n",
    "    return y.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f26565ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = torch.mean(torch.abs(calc_preds(t_indep)-t_dep))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "06b4e293-a370-4e3f-9dc9-93ba9c190a56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.2906, dtype=torch.float64, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "37d6e3c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f8fe897a",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer  =torch.optim.SGD(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "020f65eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.step()\n",
    "optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "215be08a-6aa6-4b16-8e63-566713f3faad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.2904, dtype=torch.float64, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mean(torch.abs(calc_preds(t_indep)-t_dep))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdaa2f45-94ba-44e5-ab28-36f041a91284",
   "metadata": {},
   "source": [
    "The idea is, we keep doing this for some number of iterations: calculate the model output, measure how wrong it is (i.e. the _loss_), and then adjust the weights using the optimizer.\n",
    "\n",
    "We are going to use the functions PyTorch provides to do these training steps. While we're at it we are also going to split the data into a training set and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ca62b51f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'fastai'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mfastai\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtransforms\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m RandomSplitter\n\u001b[1;32m      2\u001b[0m train_split,test_split \u001b[38;5;241m=\u001b[39m RandomSplitter(seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)(df)\n\u001b[1;32m      3\u001b[0m train_indep, test_indep \u001b[38;5;241m=\u001b[39m t_indep[train_split], t_indep[test_split]\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'fastai'"
     ]
    }
   ],
   "source": [
    "from fastai.data.transforms import RandomSplitter\n",
    "train_split,test_split = RandomSplitter(seed=42)(df)\n",
    "train_indep, test_indep = t_indep[train_split], t_indep[test_split]\n",
    "train_dep, test_dep = t_dep[train_split], t_dep[test_split]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "5ae3a087",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(nloops):\n",
    "    for i in range(nloops):\n",
    "        optimizer.zero_grad()\n",
    "        pred = calc_preds(train_indep)\n",
    "        loss = torch.mean(torch.abs(pred - train_dep))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print(f\"loop: {i}, loss: {loss:>7f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "31d4b242",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loop: 0, loss: 0.212425\n",
      "loop: 1, loss: 0.212297\n",
      "loop: 2, loss: 0.212170\n",
      "loop: 3, loss: 0.212043\n",
      "loop: 4, loss: 0.211916\n",
      "loop: 5, loss: 0.211788\n",
      "loop: 6, loss: 0.211661\n",
      "loop: 7, loss: 0.211534\n",
      "loop: 8, loss: 0.211407\n",
      "loop: 9, loss: 0.211279\n"
     ]
    }
   ],
   "source": [
    "train_model(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "da0f7ba4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.0836, -0.1562, -0.0925,  0.1516, -0.7237,  0.6614,  0.3275,  0.3220, -0.9256, -0.0205,  0.1028,  0.0375],\n",
      "        [-0.1980,  0.1385, -0.2328, -0.4433, -0.6048,  0.3697, -0.4307, -0.3428,  0.3637,  0.2890,  0.3146, -0.6060]], dtype=torch.float64,\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.0325, 0.0223], dtype=torch.float64, requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for p in model.parameters(): print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "c46e5b13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8258426785469055\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    prediction = calc_preds(test_indep)\n",
    "    results = test_dep.bool()==(prediction>0.5)\n",
    "    print(f\"Accuracy: {results.float().mean()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "57d6a4b3",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msympy\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43msympy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m1/(1+exp(-x))\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxlim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m;\n",
      "File \u001b[0;32m~/code/cicf/.venv/lib/python3.13/site-packages/sympy/plotting/plot.py:398\u001b[0m, in \u001b[0;36mplot\u001b[0;34m(show, *args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Plots a function of a single variable as a curve.\u001b[39;00m\n\u001b[1;32m    210\u001b[0m \n\u001b[1;32m    211\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    395\u001b[0m \n\u001b[1;32m    396\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    397\u001b[0m args \u001b[38;5;241m=\u001b[39m _plot_sympify(args)\n\u001b[0;32m--> 398\u001b[0m plot_expr \u001b[38;5;241m=\u001b[39m \u001b[43m_check_arguments\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    399\u001b[0m params \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparams\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    400\u001b[0m free \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/code/cicf/.venv/lib/python3.13/site-packages/sympy/plotting/utils.py:296\u001b[0m, in \u001b[0;36m_check_arguments\u001b[0;34m(args, nexpr, npar, **kwargs)\u001b[0m\n\u001b[1;32m    291\u001b[0m new_args \u001b[38;5;241m=\u001b[39m args[:\u001b[38;5;241m-\u001b[39mn] \u001b[38;5;28;01mif\u001b[39;00m n \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m args\n\u001b[1;32m    293\u001b[0m \u001b[38;5;66;03m# at this point, new_args might just be [expr]. But I need it to be\u001b[39;00m\n\u001b[1;32m    294\u001b[0m \u001b[38;5;66;03m# [[expr]] in order to be able to loop over\u001b[39;00m\n\u001b[1;32m    295\u001b[0m \u001b[38;5;66;03m# [expr, range [opt], label [opt]]\u001b[39;00m\n\u001b[0;32m--> 296\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[43mnew_args\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m, Tuple)):\n\u001b[1;32m    297\u001b[0m     new_args \u001b[38;5;241m=\u001b[39m [new_args]\n\u001b[1;32m    299\u001b[0m \u001b[38;5;66;03m# Each arg has the form (expr1, expr2, ..., range1 [optional], ...,\u001b[39;00m\n\u001b[1;32m    300\u001b[0m \u001b[38;5;66;03m#   label [optional], rendering_kw [optional])\u001b[39;00m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "import sympy\n",
    "sympy.plot(\"1/(1+exp(-x))\", xlim=(-5,5));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "ee5e9601",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_preds(x):\n",
    "    y = model(x)\n",
    "    return torch.sigmoid(y.sum(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "14201ecb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loop: 0, loss: 0.454624\n",
      "loop: 1, loss: 0.454620\n",
      "loop: 2, loss: 0.454617\n",
      "loop: 3, loss: 0.454613\n",
      "loop: 4, loss: 0.454610\n",
      "loop: 5, loss: 0.454606\n",
      "loop: 6, loss: 0.454602\n",
      "loop: 7, loss: 0.454599\n",
      "loop: 8, loss: 0.454595\n",
      "loop: 9, loss: 0.454592\n",
      "loop: 10, loss: 0.454588\n",
      "loop: 11, loss: 0.454585\n",
      "loop: 12, loss: 0.454581\n",
      "loop: 13, loss: 0.454578\n",
      "loop: 14, loss: 0.454574\n",
      "loop: 15, loss: 0.454570\n",
      "loop: 16, loss: 0.454567\n",
      "loop: 17, loss: 0.454563\n",
      "loop: 18, loss: 0.454560\n",
      "loop: 19, loss: 0.454556\n"
     ]
    }
   ],
   "source": [
    "train_model(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "6f361cf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8258426785469055\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    prediction = calc_preds(test_indep)\n",
    "    results = test_dep.bool()==(prediction>0.5)\n",
    "    print(f\"Accuracy: {results.float().mean()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "9bcd8730",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.0826, -0.1561, -0.0923,  0.1532, -0.7237,  0.6639,  0.3290,  0.3230, -0.9256, -0.0197,  0.1028,  0.0392],\n",
      "        [-0.1979,  0.1385, -0.2328, -0.4431, -0.6048,  0.3702, -0.4307, -0.3427,  0.3640,  0.2893,  0.3148, -0.6060]], dtype=torch.float64,\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.0349, 0.0227], dtype=torch.float64, requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for p in model.parameters(): print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "1185cbfa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Age',\n",
       " 'SibSp',\n",
       " 'Parch',\n",
       " 'LogFare',\n",
       " 'Sex_male',\n",
       " 'Sex_female',\n",
       " 'Pclass_1',\n",
       " 'Pclass_2',\n",
       " 'Pclass_3',\n",
       " 'Embarked_C',\n",
       " 'Embarked_Q',\n",
       " 'Embarked_S']"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fa127ec",
   "metadata": {},
   "source": [
    "Lets try this with a slightly more complicated model.\n",
    "(It addes weights to the final sum step)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "7b1bf5c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Linear(12,2, dtype=float),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(2,1, dtype=float)\n",
    ")\n",
    "def calc_preds(x):\n",
    "    y = model(x)\n",
    "    return y\n",
    "optimizer  =torch.optim.SGD(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "718f10fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loop: 0, loss: 0.379576\n",
      "loop: 1, loss: 0.379530\n",
      "loop: 2, loss: 0.379484\n",
      "loop: 3, loss: 0.379438\n",
      "loop: 4, loss: 0.379420\n",
      "loop: 5, loss: 0.379578\n",
      "loop: 6, loss: 0.379532\n",
      "loop: 7, loss: 0.379486\n",
      "loop: 8, loss: 0.379440\n",
      "loop: 9, loss: 0.379411\n",
      "loop: 10, loss: 0.379580\n",
      "loop: 11, loss: 0.379534\n",
      "loop: 12, loss: 0.379488\n",
      "loop: 13, loss: 0.379442\n",
      "loop: 14, loss: 0.379402\n",
      "loop: 15, loss: 0.379582\n",
      "loop: 16, loss: 0.379536\n",
      "loop: 17, loss: 0.379490\n",
      "loop: 18, loss: 0.379444\n",
      "loop: 19, loss: 0.379399\n",
      "loop: 20, loss: 0.379576\n",
      "loop: 21, loss: 0.379540\n",
      "loop: 22, loss: 0.379494\n",
      "loop: 23, loss: 0.379448\n",
      "loop: 24, loss: 0.379404\n",
      "loop: 25, loss: 0.379558\n",
      "loop: 26, loss: 0.379545\n",
      "loop: 27, loss: 0.379498\n",
      "loop: 28, loss: 0.379452\n",
      "loop: 29, loss: 0.379407\n",
      "loop: 30, loss: 0.379542\n",
      "loop: 31, loss: 0.379548\n",
      "loop: 32, loss: 0.379501\n",
      "loop: 33, loss: 0.379455\n",
      "loop: 34, loss: 0.379410\n",
      "loop: 35, loss: 0.379529\n",
      "loop: 36, loss: 0.379551\n",
      "loop: 37, loss: 0.379504\n",
      "loop: 38, loss: 0.379458\n",
      "loop: 39, loss: 0.379413\n",
      "loop: 40, loss: 0.379515\n",
      "loop: 41, loss: 0.379554\n",
      "loop: 42, loss: 0.379508\n",
      "loop: 43, loss: 0.379462\n",
      "loop: 44, loss: 0.379416\n",
      "loop: 45, loss: 0.379501\n",
      "loop: 46, loss: 0.379557\n",
      "loop: 47, loss: 0.379511\n",
      "loop: 48, loss: 0.379465\n",
      "loop: 49, loss: 0.379419\n",
      "loop: 50, loss: 0.379488\n",
      "loop: 51, loss: 0.379561\n",
      "loop: 52, loss: 0.379514\n",
      "loop: 53, loss: 0.379468\n",
      "loop: 54, loss: 0.379423\n",
      "loop: 55, loss: 0.379474\n",
      "loop: 56, loss: 0.379564\n",
      "loop: 57, loss: 0.379517\n",
      "loop: 58, loss: 0.379471\n",
      "loop: 59, loss: 0.379426\n",
      "loop: 60, loss: 0.379461\n",
      "loop: 61, loss: 0.379567\n",
      "loop: 62, loss: 0.379520\n",
      "loop: 63, loss: 0.379474\n",
      "loop: 64, loss: 0.379429\n",
      "loop: 65, loss: 0.379447\n",
      "loop: 66, loss: 0.379570\n",
      "loop: 67, loss: 0.379523\n",
      "loop: 68, loss: 0.379477\n",
      "loop: 69, loss: 0.379431\n",
      "loop: 70, loss: 0.379435\n",
      "loop: 71, loss: 0.379573\n",
      "loop: 72, loss: 0.379526\n",
      "loop: 73, loss: 0.379480\n",
      "loop: 74, loss: 0.379434\n",
      "loop: 75, loss: 0.379423\n",
      "loop: 76, loss: 0.379576\n",
      "loop: 77, loss: 0.379529\n",
      "loop: 78, loss: 0.379483\n",
      "loop: 79, loss: 0.379437\n",
      "loop: 80, loss: 0.379410\n",
      "loop: 81, loss: 0.379578\n",
      "loop: 82, loss: 0.379531\n",
      "loop: 83, loss: 0.379485\n",
      "loop: 84, loss: 0.379439\n",
      "loop: 85, loss: 0.379401\n",
      "loop: 86, loss: 0.379580\n",
      "loop: 87, loss: 0.379533\n",
      "loop: 88, loss: 0.379487\n",
      "loop: 89, loss: 0.379441\n",
      "loop: 90, loss: 0.379396\n",
      "loop: 91, loss: 0.379576\n",
      "loop: 92, loss: 0.379537\n",
      "loop: 93, loss: 0.379491\n",
      "loop: 94, loss: 0.379445\n",
      "loop: 95, loss: 0.379400\n",
      "loop: 96, loss: 0.379561\n",
      "loop: 97, loss: 0.379541\n",
      "loop: 98, loss: 0.379494\n",
      "loop: 99, loss: 0.379448\n",
      "loop: 100, loss: 0.379403\n",
      "loop: 101, loss: 0.379546\n",
      "loop: 102, loss: 0.379544\n",
      "loop: 103, loss: 0.379497\n",
      "loop: 104, loss: 0.379451\n",
      "loop: 105, loss: 0.379406\n",
      "loop: 106, loss: 0.379532\n",
      "loop: 107, loss: 0.379547\n",
      "loop: 108, loss: 0.379501\n",
      "loop: 109, loss: 0.379455\n",
      "loop: 110, loss: 0.379409\n",
      "loop: 111, loss: 0.379518\n",
      "loop: 112, loss: 0.379550\n",
      "loop: 113, loss: 0.379504\n",
      "loop: 114, loss: 0.379458\n",
      "loop: 115, loss: 0.379412\n",
      "loop: 116, loss: 0.379505\n",
      "loop: 117, loss: 0.379554\n",
      "loop: 118, loss: 0.379507\n",
      "loop: 119, loss: 0.379461\n",
      "loop: 120, loss: 0.379415\n",
      "loop: 121, loss: 0.379491\n",
      "loop: 122, loss: 0.379557\n",
      "loop: 123, loss: 0.379510\n",
      "loop: 124, loss: 0.379464\n",
      "loop: 125, loss: 0.379419\n",
      "loop: 126, loss: 0.379477\n",
      "loop: 127, loss: 0.379560\n",
      "loop: 128, loss: 0.379513\n",
      "loop: 129, loss: 0.379467\n",
      "loop: 130, loss: 0.379421\n",
      "loop: 131, loss: 0.379465\n",
      "loop: 132, loss: 0.379563\n",
      "loop: 133, loss: 0.379516\n",
      "loop: 134, loss: 0.379470\n",
      "loop: 135, loss: 0.379424\n",
      "loop: 136, loss: 0.379453\n",
      "loop: 137, loss: 0.379566\n",
      "loop: 138, loss: 0.379519\n",
      "loop: 139, loss: 0.379473\n",
      "loop: 140, loss: 0.379427\n",
      "loop: 141, loss: 0.379441\n",
      "loop: 142, loss: 0.379568\n",
      "loop: 143, loss: 0.379522\n",
      "loop: 144, loss: 0.379475\n",
      "loop: 145, loss: 0.379430\n",
      "loop: 146, loss: 0.379429\n",
      "loop: 147, loss: 0.379571\n",
      "loop: 148, loss: 0.379524\n",
      "loop: 149, loss: 0.379478\n",
      "loop: 150, loss: 0.379432\n",
      "loop: 151, loss: 0.379418\n",
      "loop: 152, loss: 0.379574\n",
      "loop: 153, loss: 0.379527\n",
      "loop: 154, loss: 0.379481\n",
      "loop: 155, loss: 0.379435\n",
      "loop: 156, loss: 0.379407\n",
      "loop: 157, loss: 0.379576\n",
      "loop: 158, loss: 0.379529\n",
      "loop: 159, loss: 0.379483\n",
      "loop: 160, loss: 0.379437\n",
      "loop: 161, loss: 0.379397\n",
      "loop: 162, loss: 0.379578\n",
      "loop: 163, loss: 0.379532\n",
      "loop: 164, loss: 0.379485\n",
      "loop: 165, loss: 0.379439\n",
      "loop: 166, loss: 0.379394\n",
      "loop: 167, loss: 0.379570\n",
      "loop: 168, loss: 0.379536\n",
      "loop: 169, loss: 0.379489\n",
      "loop: 170, loss: 0.379443\n",
      "loop: 171, loss: 0.379398\n",
      "loop: 172, loss: 0.379555\n",
      "loop: 173, loss: 0.379539\n",
      "loop: 174, loss: 0.379492\n",
      "loop: 175, loss: 0.379446\n",
      "loop: 176, loss: 0.379401\n",
      "loop: 177, loss: 0.379541\n",
      "loop: 178, loss: 0.379542\n",
      "loop: 179, loss: 0.379495\n",
      "loop: 180, loss: 0.379449\n",
      "loop: 181, loss: 0.379404\n",
      "loop: 182, loss: 0.379527\n",
      "loop: 183, loss: 0.379545\n",
      "loop: 184, loss: 0.379498\n",
      "loop: 185, loss: 0.379452\n",
      "loop: 186, loss: 0.379407\n",
      "loop: 187, loss: 0.379514\n",
      "loop: 188, loss: 0.379548\n",
      "loop: 189, loss: 0.379502\n",
      "loop: 190, loss: 0.379455\n",
      "loop: 191, loss: 0.379410\n",
      "loop: 192, loss: 0.379500\n",
      "loop: 193, loss: 0.379551\n",
      "loop: 194, loss: 0.379505\n",
      "loop: 195, loss: 0.379459\n",
      "loop: 196, loss: 0.379413\n",
      "loop: 197, loss: 0.379488\n",
      "loop: 198, loss: 0.379554\n",
      "loop: 199, loss: 0.379508\n"
     ]
    }
   ],
   "source": [
    "train_model(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "21e5d2e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5955055952072144\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    prediction = calc_preds(test_indep)\n",
    "    results = test_dep.bool()==(prediction>0.5)\n",
    "    print(f\"Accuracy: {results.float().mean()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "0d494155",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[-0.1960, -0.1220,  0.1653, -0.2724, -0.1901, -0.1111,  0.2767,  0.1198, -0.1633,  0.0999,  0.2361, -0.2181],\n",
       "         [-0.2748, -0.2190,  0.0676, -0.1815,  0.0796,  0.2002,  0.2100, -0.1078, -0.2290,  0.2101, -0.1251, -0.1723]], dtype=torch.float64,\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([ 0.1902, -0.0883], dtype=torch.float64, requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 0.6278, -0.3675]], dtype=torch.float64, requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([0.0003], dtype=torch.float64, requires_grad=True)]"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model.parameters())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
